{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动编码器\n",
    "自动编码器最开始是作为一种数据压缩方法，同时还可以在卷积网络中进行逐层预训练，但是随后更多结构复杂的网络，比如 resnet 的出现使得我们能够训练任意深度的网络，自动编码器就不再使用在这个方面，下面我们讲一讲自动编码器的一个新的应用，这是随着生成对抗模型而出现的，就是使用自动编码器生成数据。\n",
    "\n",
    "自动编码器的一般结构如下\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/006tNc79ly1fmzr05igw3j30ni06j3z4.jpg)\n",
    "\n",
    "由上面的图片，我们能够看到，第一部分是编码器(encoder)，第二部分是解码器(decoder)，编码器和解码器都可以是任意的模型，通常我们可以使用神经网络作为我们的编码器和解码器，输入的数据经过神经网络降维到一个编码，然后又通过另外一个神经网络解码得到一个与原始数据一模一样的生成数据，通过比较原始数据和生成数据，希望他们尽可能接近，所以最小化他们之间的差异来训练网络中编码器和解码器的参数。\n",
    "\n",
    "当训练完成之后，我们如何生成数据呢？非常简单，我们只需要拿出解码器的部分，然后随机传入 code，就可以通过解码器生成各种各样的数据\n",
    "\n",
    "![](https://ws3.sinaimg.cn/large/006tNc79ly1fmzrx3d3ygj30nu06ijs2.jpg)\n",
    "\n",
    "下面我们使用 mnist 数据集来说明一个如何构建一个简单的自动编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "\n",
    "tf.set_random_seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "train_set = mnist.train\n",
    "test_set = mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(inputs, scope='autoencoder', reuse=None):\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
    "            with tf.variable_scope('encoder'):\n",
    "                encode = slim.fully_connected(inputs, 128, scope='fc1')\n",
    "                encode = slim.fully_connected(encode, 64, scope='fc2')\n",
    "                encode = slim.fully_connected(encode, 12, scope='fc3')\n",
    "                encode = slim.fully_connected(encode, 3, activation_fn=None, scope='fc4')\n",
    "            with tf.variable_scope('decoder'):\n",
    "                decode = slim.fully_connected(encode, 12, scope='fc1')\n",
    "                decode = slim.fully_connected(decode, 64, scope='fc2')\n",
    "                decode = slim.fully_connected(decode, 128, scope='fc3')\n",
    "                decode = slim.fully_connected(decode, 28 * 28, activation_fn=tf.tanh, scope='fc4')\n",
    "            return encode, decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里定义的编码器和解码器都是 4 层神经网络作为模型，中间使用`relu`激活函数，最后输出的 code 是三维，注意解码器最后我们使用`tanh`作为激活函数，因为输入图片标准化在 -1 ~ 1 之间，所以输出也要在 -1 ~ 1 这个范围内，最后我们可以验证一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ph = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "inputs = tf.divide(input_ph - 0.5, 0.5)\n",
    "code, output = autoencoder(inputs)\n",
    "print(code.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= tf.losses.mean_squared_error(inputs, output)\n",
    "opt = tf.train.AdamOptimizer(1e-3)\n",
    "train_op = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`tf.summary.image`**\n",
    "\n",
    "我们可以给`tensorboard`添加图像元素, 来观察解码的效果是如何变化的\n",
    "\n",
    "`tf.summary.image`的参数是一个4维的张量, 最后一维的大小必须是1, 3, 4中的一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将输入重新reshape成图片形式\n",
    "gt = tf.reshape(input_ph, (-1, 28, 28, 1))\n",
    "\n",
    "# 重新reshape解码结果并变换回到[0, 1]区间\n",
    "pre = tf.reshape(output, (-1, 28, 28, 1)) * 0.5 + 0.5\n",
    "\n",
    "# 我们把原图和解码结果并排放在一起显示\n",
    "images = tf.concat([gt, pre], axis=2)[:3]\n",
    "\n",
    "# 添加`summary`\n",
    "images_sum = tf.summary.image('images', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加`summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_writer = tf.summary.FileWriter('simple_autoencoder/train', sess.graph)\n",
    "val_writer = tf.summary.FileWriter('simple_autoencoder/val', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(100):\n",
    "    num_examples = 0\n",
    "    while num_examples < train_set.num_examples:\n",
    "        if num_examples + 128 < train_set.num_examples:\n",
    "            batch = 128\n",
    "        else:\n",
    "            batch = train_set.num_examples - num_examples\n",
    "        num_examples += batch\n",
    "        train_imgs, _ = train_set.next_batch(batch)\n",
    "        train_outputs, _ = sess.run([output, train_op], feed_dict={input_ph: train_imgs})\n",
    "    if (e + 1) % 20 == 0:\n",
    "        train_imgs_sum, train_loss = sess.run([images_sum, loss], feed_dict={input_ph: train_imgs})\n",
    "        train_writer.add_summary(train_imgs_sum)\n",
    "        val_imgs, _ = test_set.next_batch(128)\n",
    "        val_imgs_sum, val_loss = sess.run([images_sum, loss], feed_dict={input_ph: val_imgs})\n",
    "        val_writer.add_summary(val_imgs_sum)\n",
    "        print('Epoch: {}, train_loss: {:.5f}, val_loss: {:.5f}'.format(e + 1, train_loss, val_loss))\n",
    "train_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完成, 我们打开`tensorboard`的`image`页面, 就会看到下面类似的内容\n",
    "\n",
    "<img src=\"https://image.ibb.co/hnWZfx/simple_autoencoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们看看编码过程的结果的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取样本\n",
    "view_imgs, view_labels = train_set.next_batch(200)\n",
    "\n",
    "# 得到编码结果\n",
    "codes = sess.run(code, feed_dict={input_ph: view_imgs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化\n",
    "x = codes[:, 0]\n",
    "y = codes[:, 1]\n",
    "z = codes[:, 2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "for X, Y, Z, S in zip(x, y, z, view_labels):\n",
    "    c = cm.rainbow(int(255 * S / 9))\n",
    "    ax.text(X, Y, Z, S, backgroundcolor=c)\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.set_ylim(y.min(), y.max())\n",
    "ax.set_zlim(z.min(), z.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，不同种类的图片进入自动编码器之后会被编码得不同，而相同类型的图片经过自动编码之后的编码在几何示意图上距离较近，在训练好自动编码器之后，我们可以给一个随机的 code，通过 decoder 生成图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_code = np.array([0.0, 0.0, 5.0]).reshape((1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里注意到`tensorflow`一个非常有用的技巧, 我们可以给不是定义成占位符的张量当作占位符喂入数据, 比如下面的`code`.\n",
    "\n",
    "可以通过`tf.Graph.is_feedable()`查看一个张量是否可以被当作占位符使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接给编码喂入元素, 查看解码结果\n",
    "decode = sess.run(output, feed_dict={code: test_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = ((decode * 0.5 + 0.5) * 255).reshape((28, 28))\n",
    "plt.imshow(decode.astype(np.uint8), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们仅仅使用多层神经网络定义了一个自动编码器，当然你会想到，为什么不使用效果更好的卷积神经网络呢？我们当然可以使用卷积神经网络来定义，下面我们就重新定义一个卷积神经网络来进行 autoencoder\n",
    "\n",
    "在使用全连接层的时候我们很容易就能够将数据进行上采样, 那么在使用卷积中也有类似功能的操作, 就是[转置卷积](https://github.com/vdumoulin/conv_arithmetic). 我们先直接使用它, 在后面图像分割 的内容中会进行详细的说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_autoencoder(inputs, scope='conv_autoencoder', reuse=None):\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose], activation_fn=tf.nn.relu, padding='SAME'):\n",
    "            with tf.variable_scope('encoder'):\n",
    "                encode = slim.conv2d(inputs, 16, 3, stride=3, scope='conv1') # (b, 10, 10, 16)\n",
    "                encode = slim.max_pool2d(encode, 2, stride=2, padding='SAME', scope='pool1') # (b, 5, 5, 16)\n",
    "                encode = slim.conv2d(encode, 8, 3, stride=2, scope='conv2') # (b, 3, 3, 8)\n",
    "                encode = slim.max_pool2d(encode, 2, stride=2, padding='SAME', scope='pool2') # (b, 2, 2, 8)\n",
    "            with tf.variable_scope('decoder'):\n",
    "                decode = slim.conv2d_transpose(encode, 16, 3, stride=2, padding='VALID', scope='trans_conv1') # (b, 5, 5, 16)\n",
    "                decode = slim.conv2d_transpose(decode, 8, 5, stride=3, scope='trans_conv2') # (b, 15, 15, 8)\n",
    "                decode = slim.conv2d_transpose(decode, 1, 3, stride=2, activation_fn=None, scope='trans_conv3') # (b, 30, 30, 1)\n",
    "                decode = tf.image.resize_bilinear(decode, (28, 28)) # (b, 28, 28, 1) 这里由于转置卷积的不可逆, 采用线性插值回到原图大小\n",
    "                decode = tf.tanh(decode)\n",
    "\n",
    "            return encode, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ph = tf.reshape(input_ph, (-1, 28, 28, 1))\n",
    "conv_input = tf.divide(conv_ph - 0.5, 0.5)\n",
    "conv_code, conv_out = conv_autoencoder(conv_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= tf.losses.mean_squared_error(conv_input, conv_out)\n",
    "opt = tf.train.AdamOptimizer(1e-3)\n",
    "train_op = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样地, 添加`summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = conv_out * 0.5 + 0.5\n",
    "images = tf.concat([conv_ph, pre], axis=2)[:3]\n",
    "images_sum = tf.summary.image('images', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_writer = tf.summary.FileWriter('conv_autoencoder/train', sess.graph)\n",
    "val_writer = tf.summary.FileWriter('conv_autoencoder/val', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(40):\n",
    "    num_examples = 0\n",
    "    while num_examples < train_set.num_examples:\n",
    "        if num_examples + 128 < train_set.num_examples:\n",
    "            batch = 128\n",
    "        else:\n",
    "            batch = train_set.num_examples - num_examples\n",
    "        num_examples += batch\n",
    "        train_imgs, _ = train_set.next_batch(batch)\n",
    "        train_outputs, _ = sess.run([output, train_op], feed_dict={input_ph: train_imgs})\n",
    "    if (e + 1) % 5 == 0:\n",
    "        train_imgs_sum, train_loss = sess.run([images_sum, loss], feed_dict={input_ph: train_imgs})\n",
    "        train_writer.add_summary(train_imgs_sum)\n",
    "        val_imgs, _ = test_set.next_batch(128)\n",
    "        val_imgs_sum, val_loss = sess.run([images_sum, loss], feed_dict={input_ph: val_imgs})\n",
    "        val_writer.add_summary(val_imgs_sum)\n",
    "        print('Epoch: {}, train_loss: {:.5f}, val_loss: {:.5f}'.format(e + 1, train_loss, val_loss))\n",
    "train_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后我们看看结果\n",
    "\n",
    "<img src=\"https://image.ibb.co/bVPn0x/conv_autoencoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们展示了简单的自动编码器，也用了多层神经网络和卷积神经网络作为例子，但是自动编码器存在一个问题，我们并不能任意生成我们想要的数据，因为我们并不知道 encode 之后的编码到底是什么样的概率分布，所以有一个改进的版本变分自动编码器，其能够解决这个问题"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

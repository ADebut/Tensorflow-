{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Tensorflow`中的循环神经网络模块\n",
    "前面我们讲了循环神经网络的基础知识和网络结构，下面我们教大家如何在`Tensorflow`下构建循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一般的 RNN\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/006tKfTcly1fmt9xz889xj30kb07nglo.jpg)\n",
    "\n",
    "对于最简单的 RNN，我们可以使用下面两种方式去调用，分别是 `tf.nn.rnn_cell.BasicRNNCell()` 和 `tf.nn.dynamic_rnn`，这两种方式的区别在于 `BasicRNNCell()` 只能接受序列中单步的输入，且必须传入隐藏状态，而 `dynamic_rnn()` 可以接受一个序列的输入，默认会传入全 0 的隐藏状态，也可以自己申明隐藏状态传入。\n",
    "\n",
    "`BasicRNNCell()` 里面的参数有\n",
    "\n",
    "num_units 表示输出的特征维度\n",
    "\n",
    "activation 表示选用的激活函数, 默认`tanh`\n",
    "\n",
    "reuse 表示是否需要复用\n",
    "\n",
    "`dynamic_rnn` 里面的参数则要丰富一些, 最重要的参数是下面的这些:\n",
    "\n",
    "inputs: 基础的`RNNCell`\n",
    "\n",
    "initial_state: 设置初始状态\n",
    "\n",
    "time_major: 确定时间步长是否在输入的第一维上, 如果是, 那么输入就是`[max_time, batch_size, depth]`的格式, 否则是`[batch_size, max_step, depth]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义一个基本的`rnn`单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-6fb2dccc9dce>:1: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "rnn_single = tf.nn.rnn_cell.BasicRNNCell(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造一个序列, 长度为6, batch是5, 特征是100\n",
    "x = tf.random_normal([6, 5, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 获取零值初始状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = rnn_single.zero_state(5, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对时间循环输出`rnn`结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取初始状态\n",
    "state = init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xinyichen/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for i in range(6):\n",
    "    # 在第一次调用`rnn_single`之后, 要重用它的元素\n",
    "    if i > 0: \n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    out, state = rnn_single(x[i], state)\n",
    "    outputs.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 200)\n",
      "[[ 0.23740672 -0.63808864 -0.44034815  0.23360763  0.2753587  -0.23616292]\n",
      " [ 0.16947421 -0.20845452  0.01050325  0.00670506  0.14466554 -0.74739504]\n",
      " [ 0.593006   -0.35832733  0.63541234  0.9081754   0.92346406 -0.8201202 ]\n",
      " [ 0.78909206 -0.60555834 -0.28283122  0.31207624  0.22151065  0.0539156 ]\n",
      " [-0.7323768  -0.58282286 -0.58387053  0.40701184  0.81881887  0.36537918]]\n"
     ]
    }
   ],
   "source": [
    "print(state.shape)\n",
    "print(sess.run(state)[:, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到, `BasicRNNCell`的状态是`[batch, num_units]`的, 我们需要在每个时间步手动去调用状态来进行结果的输出. 但这样代码显得繁琐, 我们可以通过`dynamic_rnn`将时间隐藏起来, 让它自动的去执行\n",
    "\n",
    "- `dynamic_rnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-68e612bed622>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "out, final_state = tf.nn.dynamic_rnn(rnn_single, x, initial_state=init_state, time_major=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 200)\n",
      "[[ 0.86282545 -0.1959296   0.8673103  -0.8565273  -0.02591902 -0.04155239]\n",
      " [-0.36076847  0.49511367 -0.7887822   0.24777052  0.84505177 -0.2214899 ]\n",
      " [ 0.796027    0.23960643  0.6556977  -0.54825115  0.31795624 -0.6841595 ]\n",
      " [-0.21353531  0.6054556   0.94461817  0.33738232  0.24672262  0.721434  ]\n",
      " [ 0.64385796 -0.8875018   0.8214519   0.45600793  0.7053377  -0.66932195]]\n"
     ]
    }
   ],
   "source": [
    "print(final_state.shape)\n",
    "print(sess.run(final_state)[:, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 200)\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现, `dynamic_rnn`会输出最后一步的状态和中间所有时间步的结果\n",
    "\n",
    "我们还可以自定义初始状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义初始状态由随机正态分布产生\n",
    "init_state = tf.random_normal([5, 200], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, final_state = tf.nn.dynamic_rnn(rnn_single, x, initial_state=init_state, time_major=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22710875  0.05476503 -0.42959926 -0.5678      0.44084245 -0.23703308]\n",
      " [ 0.34647667 -0.70813704 -0.8357367   0.65132725  0.23925468 -0.62708473]\n",
      " [ 0.6513476  -0.2738228   0.40910715  0.13683943 -0.88606876  0.07258287]\n",
      " [ 0.00497269  0.86790895 -0.33660704 -0.2338637  -0.48237967 -0.5952984 ]\n",
      " [ 0.05422073 -0.65117145  0.20116867  0.9408332  -0.14599302 -0.84643024]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(final_state[:, :6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RNN`训练的过程中比较容易产生过拟合的现象, 为此我们需要添加`dropout`\n",
    "\n",
    "- `RNNCell`添加`dropout`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加`dropout`正则项\n",
    "def build_rnn(num_units, batch_size, keep_prob=1):\n",
    "    cell = tf.nn.rnn_cell.BasicRNNCell(num_units)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "        \n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_cell = build_rnn(100, 3, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/006tKfTcly1fmt9qj3uhmj30iz07ct90.jpg)\n",
    "\n",
    "LSTM 和基本的 RNN 是一样的，他的参数也是相同，我们就不再赘述了\n",
    "\n",
    "在`RNN`中, 我们也可以定义深层网络, 就是通过`tf.nn.rnn_cell.MultiRNNCell`来实现, 调用它的方式非常简单, 构造一个`cell`的`list`作为参数传入就可以了\n",
    "\n",
    "- `LSTM`和`MultiRNNCell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(num_units, num_layers, batch_size, keep_prob=1):\n",
    "    def build_cell(num_units):\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(num_units, reuse=tf.AUTO_REUSE)\n",
    "        cell= tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "        \n",
    "        return cell\n",
    "    \n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([build_cell(num_units) for _ in range(num_layers)])\n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个2层的`lstm`模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-cf33a1c28d6c>:3: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-26-cf33a1c28d6c>:8: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "lstm_cell, lstm_init_state = build_lstm(100, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lstm, final_state =  tf.nn.dynamic_rnn(lstm_cell, x, initial_state=lstm_init_state, time_major=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们有了一个2层的模型, 每个模型的状态有`c`和`h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "c.shape: (5, 100)\n",
      "h.shape: (5, 100)\n",
      "layer 1\n",
      "c.shape: (5, 100)\n",
      "h.shape: (5, 100)\n"
     ]
    }
   ],
   "source": [
    "for i, layer_state in enumerate(final_state):\n",
    "    print('layer {}'.format(i))\n",
    "    print('c.shape: {}'.format(layer_state.c.shape))\n",
    "    print('h.shape: {}'.format(layer_state.h.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出形式还是相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 100)\n"
     ]
    }
   ],
   "source": [
    "print(lstm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义状态初始化\n",
    "\n",
    "有时候我们不希望用零去初始化, 考虑到`lstm`状态的特殊性, `tensorflow`用`LSTMStatusTuple`表示一个`LSTMCell`的状态, 它的参数如下\n",
    "\n",
    "`c`: 状态`c`\n",
    "\n",
    "`h`: 状态`h`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用`tuple`和`for`来定义这个2层模型的初始化状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = tuple([tf.nn.rnn_cell.LSTMStateTuple(tf.random_normal([5, 100]), tf.random_normal([5, 100])) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "c.shape: (5, 100)\n",
      "h.shape: (5, 100)\n",
      "layer 1\n",
      "c.shape: (5, 100)\n",
      "h.shape: (5, 100)\n"
     ]
    }
   ],
   "source": [
    "for i, layer_state in enumerate(init_state):\n",
    "    print('layer {}'.format(i))\n",
    "    print('c.shape: {}'.format(layer_state.c.shape))\n",
    "    print('h.shape: {}'.format(layer_state.h.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm, final_state =  tf.nn.dynamic_rnn(lstm_cell, x, initial_state=init_state, time_major=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU\n",
    "![](https://ws3.sinaimg.cn/large/006tKfTcly1fmtaj38y9sj30io06bmxc.jpg)\n",
    "\n",
    "GRU 和前面讲的这两个是同样的道理，就不再细说，还是演示一下例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru(num_units, num_layers, batch_size, keep_prob=1):\n",
    "    def build_cell(num_units):\n",
    "        cell = tf.nn.rnn_cell.GRUCell(num_units, reuse=tf.AUTO_REUSE)\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "            \n",
    "        return cell\n",
    "    \n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([build_cell(num_units) for _ in range(num_layers)])\n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_cell, gru_init_state = build_gru(100, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gru_init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru, final_state =  tf.nn.dynamic_rnn(gru_cell, x, initial_state=gru_init_state, time_major=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
